---
title: "Ana Grisanti - WB STC R Assessment"
---

## Basic Stats

```{r}
rm(list = ls())

#Loading WDI dataset
tag      <- "202311081903"
base_url <- "https://github.com/randrescastaneda/pub_data/raw/"
data_url <- paste0(base_url, tag, "/data/Rtest1/")

wdi <- readr::read_rds(paste0(data_url, "wdi_in1.Rds"))

#Installing necessary packages and libraries
install.packages('doBy')
library('doBy')
library(collapse)
library(dplyr)
library(tidyverse)
```

1.  Summary Statistics of GDP per capita by region

```{r}
#Generating new dataset with summary statistics of GDP per capita, by region and year
rep1_df<- wdi %>% drop_na(gdp)
rep1_df<-rep1_df%>%
   group_by(region, date) %>%
   summarise(N=n(),
             Mean= weighted.mean(gdp,pop),
             SD= sd(gdp),
             Min= min(gdp),
             Max= max(gdp))

#FINAL OUTPUT
write.csv(rep1_df, "./output/ReplicateDF_Q1.csv", row.names=FALSE)

#Checking similarity to original data
org1_df <- readr::read_rds(paste0(data_url, "wdi_summ_out.Rds"))
waldo::compare(rep_gdp_df, org_gdp_df)
```

2.  Aggregate stats

#FINAL REPLICATED DATAFRAME

View(rep2_df)

```{r}
#Checking data to replicate 
org2_df<- readr::read_rds(paste0(data_url, "wdi_agg_out.Rds"))

#Generating new dataset with descriptive statistics of gdp, lifeex, and pov_intl
rep2_df<- collap(wdi, by = ~ region + date, 
       custom = list(fmean = .c(lifeex, gdp, pov_intl),
                     fsd = .c(lifeex, gdp, pov_intl),
                     fmax_uw = .c(lifeex, gdp, pov_intl),
                     fmin_uw = .c(lifeex, gdp, pov_intl),
                     fmedian = .c(lifeex, gdp, pov_intl)),
       w = ~ pop)

#Converting the data to long format
rep2_df_gdp <- rep2_df %>%
  gather(estimate, gdp, fmean.gdp:fmedian.gdp, factor_key=TRUE)
rep2_df_lifeex <- rep2_df %>%
  gather(estimate, lifeex, fmean.lifeex:fmedian.lifeex, factor_key = TRUE)
rep2_df_povintl <- rep2_df %>%
  gather(estimate, pov_intl, fmean.pov_intl:fmedian.pov_intl, factor_key = TRUE)

#Keeping only necessary variables
rep2_df_gdp = rep2_df_gdp[c("estimate","region", "date", "pop", "gdp")]
rep2_df_lifeex = rep2_df_lifeex[c("estimate","region", "date", "pop", "lifeex")]
rep2_df_povintl = rep2_df_povintl[c("estimate","region", "date", "pop", "pov_intl")]

#Cleaning up estimate variable
rep2_df_gdp$estimate <- gsub(".*fmean.*", "Mean", rep2_df_gdp$estimate)
rep2_df_gdp$estimate <- gsub(".*fsd.*", "SD", rep2_df_gdp$estimate)
rep2_df_gdp$estimate <- gsub(".*fmin.*", "Min", rep2_df_gdp$estimate)
rep2_df_gdp$estimate <- gsub(".*fmax.*", "Max", rep2_df_gdp$estimate)
rep2_df_gdp$estimate <- gsub(".*fmedian.*", "Median", rep2_df_gdp$estimate)
#Cleaning up estimate variable
rep2_df_lifeex$estimate <- gsub(".*fmean.*", "Mean", rep2_df_lifeex$estimate)
rep2_df_lifeex$estimate <- gsub(".*fsd.*", "SD", rep2_df_lifeex$estimate)
rep2_df_lifeex$estimate <- gsub(".*fmin.*", "Min", rep2_df_lifeex$estimate)
rep2_df_lifeex$estimate <- gsub(".*fmax.*", "Max", rep2_df_lifeex$estimate)
rep2_df_lifeex$estimate <- gsub(".*fmedian.*", "Median", rep2_df_lifeex$estimate)
#Cleaning up estimate variable
rep2_df_povintl$estimate <- gsub(".*fmean.*", "Mean", rep2_df_povintl$estimate)
rep2_df_povintl$estimate <- gsub(".*fsd.*", "SD", rep2_df_povintl$estimate)
rep2_df_povintl$estimate <- gsub(".*fmin.*", "Min", rep2_df_povintl$estimate)
rep2_df_povintl$estimate <- gsub(".*fmax.*", "Max", rep2_df_povintl$estimate)
rep2_df_povintl$estimate <- gsub(".*fmedian.*", "Median", rep2_df_povintl$estimate)

#Merging dataframes
merged <- merge(rep2_df_gdp, rep2_df_lifeex, by=c("estimate","region", "date", "pop"))
rep2_df <- merge(merged, rep2_df_povintl, by=c("estimate","region", "date", "pop"))
rm(merged, rep2_df_, rep2_df_gdp, rep2_df_lifeex, rep2_df_povintl)

#FINAL OUTPUT
write.csv(rep2_df, "./output/ReplicateDF_Q2.csv", row.names=FALSE)

#Checking for similarity with original datagrame
waldo::compare(rep2_df, org2_df)

```

3.  Find outliers

```{r}
org3_df<-readr::read_rds(paste0(data_url, "wdi_outliers_out.Rds"))

#Generating dataset with mean and sd of lifeex, gdp and gini
df_summary <- wdi %>% 
  group_by(date) %>% 
  summarise(gdp.mean = weighted.mean(gdp, pop, na.rm=TRUE),
            gini.mean= weighted.mean(gini, pop, na.rm=TRUE),
            lifeex.mean= weighted.mean(lifeex, pop, na.rm=TRUE),
            gdp.sd = sd(gdp, na.rm=TRUE),
            gini.sd= sd(gini, na.rm=TRUE),
            lifeex.sd= sd(lifeex, na.rm=TRUE))

#Joining original data with summary 
rep3_df <- left_join(wdi, df_summary, by = "date")

#Generating outlier identifying variables
rep3_df <- rep3_df %>%
  mutate(ll_gdp = print(gdp < gdp.mean - 2.5*(gdp.sd))) %>%
  mutate(hl_gdp = print(gdp > gdp.mean + 2.5*(gdp.sd))) %>%
  mutate(ll_gini = print(gini < gini.mean - 2.5*(gini.sd))) %>%
  mutate(hl_gini = print(gini > gini.mean + 2.5*(gini.sd))) %>%
  mutate(ll_lifeex = print(lifeex < lifeex.mean - 2.5*(lifeex.sd))) %>%
  mutate(hl_lifeex = print(lifeex > lifeex.mean + 2.5*(lifeex.sd)))

#Checking for similarity with original datagrame
waldo::compare(rep3_df, org3_df)

#FINAL OUTPUT
write.csv(rep3_df, "./output/ReplicateDF_Q3.csv", row.names=FALSE)
```

4.  Poverty measures

```{r}
#Loading the data
l_svy <-readr::read_rds(paste0(data_url, "svy_sim_in1.Rds"))

org4_df <- readr::read_rds(paste0(data_url, "dt_pov_out.Rds"))

#Calculating headcount vectors for incomes under $2.15, $3.65 and $6.85
headcount215 <- vector(mode="numeric")
number <- 1:10
for(i in number) {
    result <- sum(print(l_svy[[i]][1]<2.15))/100000
    headcount215 <- append(headcount215, result)
}

headcount365 <- vector(mode="numeric")
number <- 1:10
for(i in number) {
    result <- sum(print(l_svy[[i]][1]<3.65))/100000
    headcount365 <- append(headcount365, result)
}

headcount685 <- vector(mode="numeric")
number <- 1:10
for(i in number) {
    result <- sum(print(l_svy[[i]][1]<6.85))/100000
    headcount685 <- append(headcount685, result)
}

#Creating a dataframe for headcount calculations
year <- 2001:2010
headcount_df <- data.frame(year, headcount215, headcount365, headcount685) 

#Calculating poverty gap
povertygap215 <- vector(mode="numeric")
number <- 1:10
for(i in number) {
  avrginc <- sum(l_svy[[i]][1]*print(l_svy[[i]][1]<2.15))/sum(print(l_svy[[i]][1]<2.15))
  povertyratio <- (2.15 - avrginc)/2.15
  headcount <- sum(print(l_svy[[i]][1]<2.15))/100000
  povertygap <- headcount*povertyratio
  povertygap215 <- append(povertygap215, povertygap)
}

povertygap365 <- vector(mode="numeric")
number <- 1:10
for(i in number) {
  avrginc <- sum(l_svy[[i]][1]*print(l_svy[[i]][1]<2.15))/sum(print(l_svy[[i]][1]<3.65))
  povertyratio <- (3.65 - avrginc)/3.65
  headcount <- sum(print(l_svy[[i]][1]<3.65))/100000
  povertygap <- headcount*povertyratio
  povertygap365 <- append(povertygap365, povertygap)
}

povertygap685 <- vector(mode="numeric")
number <- 1:10
for(i in number) {
  avrginc <- sum(l_svy[[i]][1]*print(l_svy[[i]][1]<6.85))/sum(print(l_svy[[i]][1]<6.85))
  povertyratio <- (6.85 - avrginc)/6.85
  headcount <- sum(print(l_svy[[i]][1]<6.85))/100000
  povertygap <- headcount*povertyratio
  povertygap685 <- append(povertygap685, povertygap)
}

#Creating a dataframe for povertygap calculations
povertygap_df <- data.frame(year, povertygap215, povertygap365, povertygap685) 

#Datasets from wide to long
headcount_df <- headcount_df %>%
  gather(pov_line, headcount, headcount215:headcount685, factor_key=TRUE)
headcount_df$pov_line <- gsub(".*215.*", "2.15", headcount_df$pov_line)
headcount_df$pov_line <- gsub(".*365.*", "3.65", headcount_df$pov_line)
headcount_df$pov_line <- gsub(".*685.*", "6.85", headcount_df$pov_line)

povertygap_df <- povertygap_df %>%
  gather(pov_line, povertygap, povertygap215:povertygap685, factor_key=TRUE)
povertygap_df$pov_line <- gsub(".*215.*", "2.15", povertygap_df$pov_line)
povertygap_df$pov_line <- gsub(".*365.*", "3.65", povertygap_df$pov_line)
povertygap_df$pov_line <- gsub(".*685.*", "6.85", povertygap_df$pov_line)

#Merging long datasets
rep4_df <- merge(headcount_df, povertygap_df, by=c("year","pov_line"))

#FINAL OUTPUT -- I got different results likely because I did not use the weights. I was not sure how to incorporate this part into the calculations. With more time I might have been able to do so.
write.csv(rep4_df, "./output/ReplicateDF_Q4.csv", row.names=FALSE)
```
